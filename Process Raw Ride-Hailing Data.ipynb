{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys \n",
    "import datetime\n",
    "import os\n",
    "import matplotlib as plt\n",
    "import geopandas as gp\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = {'Fare':'mean','Trip Total':'mean','Trip Miles':'sum','Trips Pooled':'sum','PRIVATE_TRIPS':'sum','SHARED_TRIPS':'sum','TRIPS':'sum'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_float_cols(x):\n",
    "    x = x.replace(',','')\n",
    "    x = float(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processRawData(infile, outfile):\n",
    "        \"\"\"\n",
    "        Reads data, cleans it, processes it, and writes it to an HDF5 file.\n",
    "        \n",
    "        infile  - infile name, raw CSV format\n",
    "        outfile - output file name, h5 format\n",
    "        outkey = name of table in output h5 file\n",
    "        \"\"\"\n",
    "        \n",
    "        print(datetime.datetime.now().ctime(), 'Converting raw data in file: ', infile)\n",
    "        \n",
    "        # set up the reader\n",
    "        reader = pd.read_csv(infile,  \n",
    "                         iterator = True, \n",
    "                         sep = ',', \n",
    "        parse_dates = ['Trip Start Timestamp','Trip End Timestamp'], infer_datetime_format = True, chunksize= 25000)\n",
    "\n",
    "        # establish the writer and clear any table with that file name\n",
    "        store = pd.HDFStore(outfile)\n",
    "\n",
    "        # iterate through chunk by chunk so the computer doesn't run out of memory\n",
    "        rowsRead    = 0\n",
    "        rowsWritten_weekday = 0\n",
    "        rowsWritten_weekend = 0\n",
    "        \n",
    "        for chunk in reader:   \n",
    "\n",
    "            rowsRead += len(chunk)\n",
    "            \n",
    "            #convert columns from a string because it caused problems\n",
    "            convert_cols = ['Trip Seconds','Trip Miles', 'Pickup Census Tract', 'Dropoff Census Tract','Fare', \n",
    "                            'Tip','Additional Charges', 'Trip Total', 'Trips Pooled']\n",
    "        \n",
    "            for column in convert_cols:\n",
    "                chunk[column] = chunk[column].astype(str).apply(lambda x: x.replace(',',''))\n",
    "                chunk[column] = chunk[column].astype(float)\n",
    "           \n",
    "            chunk['YEAR'], chunk['MONTH'], chunk['DOW'], chunk['HOUR'] = chunk['Trip Start Timestamp'].dt.year, chunk['Trip Start Timestamp'].dt.month, chunk['Trip Start Timestamp'].dt.weekday, chunk['Trip Start Timestamp'].dt.hour\n",
    "            \n",
    "            chunk_weekday = chunk[chunk['DOW'].isin([0,1,2,3,4])]\n",
    "            chunk_weekend = chunk[chunk['DOW'].isin([5,6])]\n",
    "\n",
    "            chunk_weekday_2 = chunk_weekday[chunk_weekday['HOUR'].isin([6])]\n",
    "            chunk_weekday_3 = chunk_weekday[chunk_weekday['HOUR'].isin([7,8])]\n",
    "            chunk_weekday_4 = chunk_weekday[chunk_weekday['HOUR'].isin([9])]\n",
    "            chunk_weekday_5 = chunk_weekday[chunk_weekday['HOUR'].isin([10,11,12,13])]\n",
    "            chunk_weekday_6 = chunk_weekday[chunk_weekday['HOUR'].isin([14,15])]\n",
    "            chunk_weekday_7 = chunk_weekday[chunk_weekday['HOUR'].isin([16,17])]\n",
    "            chunk_weekday_8 = chunk_weekday[chunk_weekday['HOUR'].isin([18,19])]\n",
    "            chunk_weekday_1 = chunk_weekday[chunk_weekday['HOUR'].isin([20,21,22,23,24,1,2,3,4,5])]\n",
    "            \n",
    "            chunk_weekend_2 = chunk_weekend[chunk_weekend['HOUR'].isin([6])]\n",
    "            chunk_weekend_3 = chunk_weekend[chunk_weekend['HOUR'].isin([7,8])]\n",
    "            chunk_weekend_4 = chunk_weekend[chunk_weekend['HOUR'].isin([9])]\n",
    "            chunk_weekend_5 = chunk_weekend[chunk_weekend['HOUR'].isin([10,11,12,13])]\n",
    "            chunk_weekend_6 = chunk_weekend[chunk_weekend['HOUR'].isin([14,15])]\n",
    "            chunk_weekend_7 = chunk_weekend[chunk_weekend['HOUR'].isin([16,17])]\n",
    "            chunk_weekend_8 = chunk_weekend[chunk_weekend['HOUR'].isin([18,19])]\n",
    "            chunk_weekend_1 = chunk_weekend[chunk_weekend['HOUR'].isin([20,21,22,23,24,1,2,3,4,5])]\n",
    "            \n",
    "            \n",
    "            # write the data\n",
    "            store.append('Weekday_1', chunk_weekday_1, data_columns = True)\n",
    "            store.append('Weekday_2', chunk_weekday_2, data_columns = True)\n",
    "            store.append('Weekday_3', chunk_weekday_3, data_columns = True)\n",
    "            store.append('Weekday_4', chunk_weekday_4, data_columns = True)\n",
    "            store.append('Weekday_5', chunk_weekday_5, data_columns = True)\n",
    "            store.append('Weekday_6', chunk_weekday_6, data_columns = True)\n",
    "            store.append('Weekday_7', chunk_weekday_7, data_columns = True)\n",
    "            store.append('Weekday_8', chunk_weekday_8, data_columns = True)\n",
    "\n",
    "            store.append('Weekend_1', chunk_weekend_1, data_columns = True)\n",
    "            store.append('Weekend_2', chunk_weekend_2, data_columns = True)\n",
    "            store.append('Weekend_3', chunk_weekend_3, data_columns = True)\n",
    "            store.append('Weekend_4', chunk_weekend_4, data_columns = True)\n",
    "            store.append('Weekend_5', chunk_weekend_5, data_columns = True)\n",
    "            store.append('Weekend_6', chunk_weekend_6, data_columns = True)\n",
    "            store.append('Weekend_7', chunk_weekend_7, data_columns = True)\n",
    "            store.append('Weekend_8', chunk_weekend_8, data_columns = True)\n",
    "\n",
    "            rowsWritten_weekday += len(chunk_weekday)\n",
    "            rowsWritten_weekend += len(chunk_weekend)\n",
    "\n",
    "            print ('Read %i rows and kept %i rows in weekday TNC table' % (rowsRead, rowsWritten_weekday))\n",
    "            print ('kept ' + str(rowsWritten_weekend) + ' rows in weekend TNC table')\n",
    "\n",
    "        store.close()\n",
    "        print('Complete!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the shared TNC trip h5 table\n",
    "processRawData('C:/Workspace/TNC-Demand-Model/Inputs/Chicago Ride-Hailing/Transportation_Network_Providers_-_Trips.csv', 'C:/Workspace/TNC-Demand-Model/Inputs/Chicago Ride-Hailing/Chicago_TNC_Trips_20.H5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
